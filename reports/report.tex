\documentclass{report}
\input{preamble.tex}
\usepackage[english,vlined,linesnumbered]{algorithm2e}
\usepackage{url}
\usepackage{pgf}
\usepackage{pgfplots}


\pgfplotsset{
	legend style={rounded corners=2pt},
}

\title{Machine Learning Project Report\\\textbf{Evolutionary Computing\\on Turing machines}\\{\Large Solving the Busy Beaver Problem}}
\author{Jean-Florent Raymond\\\href{mailto:jean-florent.raymond.8795@student.uu.se}{\texttt{jean-florent.raymond.8795@student.uu.se}} \and Emilio Del Tessandoro\\
  \href{mailto:emilio.del_tessandoro.4062@student.uu.se }{\texttt{emilio.del\_tessandoro.4062@student.uu.se }}}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}

  Busy beavers are Turing machines that performs ``the most operations'' before halting among all Turing machines with the same alphabet and number of states. The concept has been introduced in 1962 by Tibor Rad√≥ and Shen Lin, and there are theoretical issues that make finding the busy beavers a very challenging problem.
The goal of our project is to see if evolutionary computing techniques are suitable for finding busy beavers. We implemented such approach and we found that is possible to solve the problem at least for small values of the alphabet size and the number of the states.
%We have to sell!
%The resolution becomes much more difficult for the unknown cases, since the search space size and the number of shifts to execute increase dramatically.

\end{abstract}

\chapter{Introduction}
\label{chap:intro}

Given an alphabet and a set of states, we want to find a Turing machine that performs the most shifts before halting. 
Finding these machines is very difficult for mainly two reasons: the halting problem and the huge number of possible candidates.
The usual approaches \cite{rado} to this problem are:
\begin{itemize}
\item running different machines (eventually all of them, if they are not too many) until it halts (if so) and keeping the best.
\item detecting patterns on the tape that means that the machine will stop after a certain number of shifts.
\end{itemize}
These methods can be improved using techniques of loop detection or by predicting the configuration of the machine in a certain number of steps given the tape and the transition table. The main problem of this is that the search space size hugely increases with the size of the machines, as well as the most shifts performed by a busy beaver.


Our approach is different. We use a genetic algorithm to find busy beavers. We have a population of Turing machines and we perform operations on it until it lead to a busy beaver.

For this, we designed and wrote a program to handle and execute Turing machines, and a program to simulate evolution on a population of Turing machines.

With this method, we were able to find busy beavers for small machine sizes. We are sure that these are busy beavers because the maximum number of steps before halting is known for these machine sizes. When the machine size grows, we have to deal with the same problem as above; and we were out of time to run the experiments long enough to be able to find good candidates. However, no busy beaver is known for these sizes at the time of writing this paper. Only lower bounds are know for some sizes.

\chapter{Definitions and Conventions}
\label{chap:pre}

\section{Machines}
\label{sec:ma}

We assume that the reader is familiar with the notion of Turing machine. In this paper, we only use deterministic Turing machines so it is what we mean when we use the expression \emph{Turing machine}. The tape is infinite on both sides.

\paragraph{Symbols}
We only deal with Turing machines with a finite alphabet. So we can represent it by an initial segment of $\N$. Furthermore, we choose that $0$ is the blank symbol. Our input alphabet is always $\{0\}$ since we only start on blank tapes. 

\paragraph{States}
Turing machines we are working with have a finite set of states and only one halt state.
 Except where otherwise stated, when we write that a Turing machine have $n$ states, we mean $n$ \emph{operational} states, \ie states that are not halt states. We use to use the letter $m$ to denote the cardinality of the alphabet and the letter $n$ to denote the cardinality of the operational states set.

 Let $\mathcal{T}_{m,n}$ be the set of deterministic Turing machines with an alphabet of $m$ symbols which uses $n + 1$ states, one of whom is the halt state, reached at most one time (because then the machine halts). Let  $\mathcal{T} = \cup_{n,m \in \N} \mathcal{T}_{n,m}$.

Since we only deals with finite states sets, we chose without loss of generality to represent any state set by an initial segment of $\N$ of the corresponding size. For instance, a machine $M \in \mathcal{T}_{m,n}$ have $\intv{0}{n}$ as states set and $\intv{0}{m-1}$ as alphabet.

What is more, since states names are interchangeable (with modifying the transition table according to this change), we chose that the start state is always state $0$ and the (maybe never reached) halting state is always state $n$.



\paragraph{Machines}
All the assumptions we do simplifies the representation of machines so we can now define it easily.

\begin{Def}[Turing machine]

A \emph{Turing machine} $M$ of $\mathcal{T}$ is a triple $(m,n,\delta)$ where 
\[
\left \{
\begin{array}{l}
  n \in \N^*\\
  m \in \N^*\\
  \delta : \intv{0}{m-1} \times \intv{0}{n-1} \to \intv{0}{m-1} \times \intv{0}{n} \times \{0,1\}
\end{array}
\right .
\]
The function $\delta$ is the transition function and $\delta(a, s) = (a', s', d)$ means that if the machine is in the state $s$ and reads the symbol $a$, it writes $a'$, pass in state $s'$ and move in a direction given by $d$ where $d = 0$ means \emph{left} and $d = 1$ means \emph{right}. This function cannot be used on state $n$ since there is no transition from the halt state.  
\end{Def}


\section{Busy Beavers}
\label{sec:bb}

Busy beavers are about the number of operations performed by Turing machines so we need a function to express this value.
\begin{Def}[$s$ function]
  $s : \mathcal{T} \to \N \cup \{-1\}$ is the function which, given a Turing machine $M$, returns
  \begin{itemize}
  \item either the number of steps that $M$ performs when started on a blank tape, if $M$ halts;
  \item or minus one else.
  \end{itemize}
\end{Def}

We also want to be able to talk about the machine that realizes this score.
\begin{Def}[max-step function]
$S$ is the function defined by
\[
S : \left |
  \begin{array}{l}
    \N \times \N \to \N\\
    (m,n) \mapsto \max_{M \in \mathcal{T}_{m,n}} s(M)
  \end{array}
\right .
\]
$S$ is called the \emph{max-step} function.
\end{Def}

We use these functions to define a busy beaver as following.

\begin{Def}[busy beaver]
\emph{busy beaver} of $\mathcal{T}_{m,n}$ is a Turing machine $M \in \mathcal{T}_{m,n}$ such that \[s(M) = S(m,n)\] In other words, it is a machine that performs the most shifts among all machines of $\mathcal{T}_{m,n}$. 
\end{Def}


Our goal here is to find a busy beaver of $\mathcal{T}_{m,n}$ for given values $m,n\in\N^*$.


\begin{Rem}
  The functions $s$ and $S$ are not computable because otherwise it would means that we can decide the halting problem. In fact, if we assume that $s$ is computable, then the function $H : \mathcal{T} \to \{0,1\}$ such that
  \[
  \forall M \in \mathcal{T},\ H(M) =
  \left \{
    \begin{array}{l}
      0\quad \ \text{if}\ s(M) = -1\\
      1\quad \ \text{else}
    \end{array}
  \right .
  \]
  is computable too. This function decides the halting problem, that is absurd \cite{turing}. So $s$ is not computable and we can get the same result for $S$ by the same token.
\end{Rem}

\begin{Rem}
  Alternative definitions of busy beavers exists. For instance, we can want to find machines that leave the most symbols on the tape when halting (if so) \cite{rado}.
\end{Rem}

\chapter{Strategy}
\label{chap:strategy}

\section{The Genetic Algorithm}
\label{sec:genalg}
Given a machine size, \ie two integers $m$ (size of the alphabet) and $n$ (number of states), we use a genetic algorithm in order to find busy beavers of $\mathcal{T}_{mn}$. The procedure is the following.

\begin{enumerate}
\item we generate a population of random individuals. Here these individuals are Turing machines of current state 0 (initial state), with a blank tape (filled with zeroes) and with a random transition table;
\item \label{en:go} we perform genetic operations on a random part of the population (see section \ref{sec:go} for more detail);
\item we compute the value of a fitness function (explained in section \ref{sec:fitness}) for each individual, what make possible to rank them;
\item we pick some individuals from the population and we delete it. This choice depends on the value of the fitness function for these individuals but it is also \textit{stochastic}. It simulates the natural selection of ``good'' individuals. More details about the implementation of this part can be found in section \ref{sec:select} (on page \pageref{sec:select});
\item we come back to \ref{en:go} until we perform as much generations as we wanted or until we find a busy beaver.
\end{enumerate}

\section{Genetic Operations}
\label{sec:go}

The genotype of our individuals is only the transition table. In fact, it would be totally meaningless to act on the tape or the current state since the machines we are looking for (busy beavers) starts on a blank tape in state 0, so they are only defined by their transition table.
The operators we use are crossover and mutations.
See sections \ref{sec:crossover} (on page \pageref{sec:crossover}) and \ref{sec:mutation} (on page \pageref{sec:mutation}) for implementation details of the genetic operators. 

\section{A Difficult Problem}

Three features of busy beaver problem makes it difficult:
\begin{enumerate}
\item the fitness function is hard to define and to compute. This will be discussed later in section \ref{sec:fitness};
\item \label{en:se} the search space is wide.
\item the distribution of the machines that compute the most steps is not simple. For example for the 2 state, 4 symbol problem it has been proven \cite{michel} that there is no machine that performs a number of shifts between 7195 and 3932964 (current best contender).
\end{enumerate}

On point \ref{en:se}, we can be more accurate. As we saw in section \ref{sec:go}, the genotype of our individuals is nothing more than the transition table, so there is clearly as different individuals as there is different transition functions.

These functions are, according to section \ref{sec:ma}, of the following type
\[
  \delta : \intv{0}{m-1} \times \intv{0}{n-1} \to \intv{0}{m-1} \times \intv{0}{n} \times \{0,1\}
\]

The function $\delta$ is from a set of $|\intv{0}{m-1} \times \intv{0}{n-1}| = nm$ elements to a set of $|\intv{0}{m-1} \times \intv{0}{n} \times \{0,1\}| = 2m(n+1)$ elements. So for each of the $nm$ different possible arguments of $\delta$, we can choose between $2m(n+1)$ values.
It follows that we can have $(2 m (n+1))^{mn}$ different transition functions.

According to what we said before, this is also the size of the search space. It grows very fast, as we can see from the following table that shows its first values; lines are indexed by number of states ($n$) and columns by the alphabet size ($m$).

\[
\begin{array}{|c|c|c|c|c|}
  \hline
    & 2         & 3              & 4\\
  \hline
  2 & 20736     &34012224          &531441000000000000\\
  \hline
  3 &16777216   &2641807540224     &1152921504606846976\\
  \hline
  4 &25600000000&531441000000000000&42949672960000000000000000\\
  \hline
\end{array}
\]

\section{The fitness function}
\label{sec:fitness}

Fitness functions are about what is ``good'' in an individual and what nature we want to promote or blame.
In the case we are interested in, we wants machines which runs for long time and then halt. So we have to discard machines that loop, and, among non-looping machines, give best fitness to machines that runs longer.

However, there is a big theoretical issue that makes it impossible. Because of the halting problem \cite{turing}, there is no general way to know if a given machine will stop or not. Of course, we can see in a glance that some machines will loop for ever. But we cannot write, in general, a function that take a transition table and answer yes or no depending of if the machine loops or not. So defining a good fitness function becomes really tricky.

However, previous work on busy beavers \cite{rado} \cite{allen} \cite{michel} gives us, at least for few values of $m$ and $n$ the values the the max step function. So we know that if a machine overtake the value of this function, this machine loops for sure (because max step is the maximum number of steps performed by halting machines). Then, in the case of we know the value of max step, the fitness function can be something like

\[
f : \left |
  \begin{array}{l}
    \mathcal{T}_{mn} \to \R\\
    M  \mapsto \left \{
  \begin{array}{ll}
    0&\text{if } M \text{ is still running after } S(m,n) \text{ steps}\\
    \frac{1}{S(m,n) - h + 1}&\text{else, if } M \text{ halts after } h \text{ steps}
  \end{array} \right .
  \end{array}
\right .
\]

So we have to run machines for $S(m,n)$ steps to be able to compute their exact fitness. We do this progressively and then compute an approximation of the fitness function, as explained in the implementation chapter, section \ref{sec:fit} on page \pageref{sec:fit}.

For values of $m$ and $n$ where the max step function is not known, this approach is impossible. Our implementation choice for this case is explained in the section \ref{sec:fit} on page \pageref{sec:fit}.

\chapter{Implementation}
\label{chap:impl}

\section{Random numbers}
\label{sec:random}
We used a small class that embeds one \texttt{boost} random number generator, in particular the Mersenne Twister generator. This implementation is very fast and provides very good quality randomness also in high dimensional spaces \cite{boost-random}, \cite{mersenne-twister}.

We used random numbers very often in our program, especially for taking probabilistic decisions. Suppose in fact we want to implement a decision function $f$ that returns true with probability $p$. Something like this has been used in the selection procedure and in the individuals selection for crossovers and mutations.

This is very easily implemented as shown in the algorithm at page \pageref{alg:decision}.

\begin{algorithm}[t]
\caption[Probabilistic decision]{A simple probabilistic decision procedure}
\label{alg:decision}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwFunction{random}{random}

\Input{A real number $p$ representing the probability of taking the decision}
\Begin{
	\If{\random{} $< p $}{
		\Return{true}\;
	}
	\Else{
		\Return{false}\;	
	}
}
\end{algorithm}

\section{Turing Machine}
Our representation of a Turing Machine is simply a table of transitions. Every transition (file \texttt{action.hpp}) have three variables:
\begin{enumerate}
\item the direction in which move the tape.
\item the symbol to write on the tape.
\item the next state.
\end{enumerate}
A transition can be indexed with a given (current) state and a given (current) symbol. It's easier to think at a transition \textit{table} but actually we implemented it as a plain array of transitions.

Of course we enriched the implementation with several utility functions like random initialization (see \ref{sec:random}), serialization (using \texttt{boost} libraries \cite{boost-serialization}) and genetic operators.

We implemented crossovers and mutations here since they depends on the representation of the individual type: the population method is not aware of \textit{how} we implement for example the transition table. Actually we could have some flags (like in Matlab) like: ``it is a string'', ``it is a bit string'', etc. But, since the key point of all our work are probably also these two functions, we preferred to implement them where we have all the details of the individual representation, the Turing Machine.

\subsection{Crossover}
\label{sec:crossover}
We implemented 3 types of crossover: \texttt{ONE\_POINT}, \texttt{TWO\_POINT} and \texttt{UNIFORM}, with the meaning that we gave during the course. The only thing we need to clear is ``what is a point'' for our data type, for example one can think to a bit offset in the transitions array, or to a byte offset, or more.
We actually implemented two versions for the \texttt{TWO\_POINT} crossover, using two different genome units:

\begin{enumerate}
\item For the first, the genome unit is a variable inside the transition table. So in practice what we do is to choose the addresses of two variables in the transition table and the swap all the genome portion between them.
\item The second correspond to see the genome as an array of transitions, so we choose two transition indexes at random and we swap all the date between them.
\end{enumerate}

The first version obviously can create more new individuals than the second, since we have more possibilities for the points to choose. But in practice we didn't notice big differences between the two, and we preferred the second one for its simplicity.

\subsection{Mutation}
\label{sec:mutation}
A mutation clearly is intended as a mutation of the transition table, so we implemented it in the Turing Machine class. It simply changes one single variable in the transition table (the variable changes for sure if the mutation happens, the old value cannot be chose).



\section{Virtual Machine}
The virtual machine is implemented in the file \texttt{living-tm.hpp}. It encloses a transition table and adds some vital variables for executing a Turing Machine like:

\begin{enumerate}
\item The tape. We needed a data structure that can grows dynamically both in the left and in the right direction. \texttt{std::deque} perfectly fit this task.
\item The tape position. It is simply an index in the \texttt{deque}.
\item The current state.
\end{enumerate}

We tested the implementation running the current 5 state, 2 symbols best busy beaver contender, that executes exactly 47176870 steps before reaching the halting state. The program, besides executing the right number of shifts, also completes very very quickly (about 1 second of calculation).

\subsection{Fitness function}
\label{sec:fit}
The fitness function is a relatively easy implementation, but reasoning behind it is very tricky and is better explained in \ref{sec:fitness}.

As said in section \ref{sec:fitness}, there is two different cases we have to to deal with, depending on values of $m$ (alphabet size) and $n$ (number of states):
\begin{enumerate}
\item the max step value is known. For each generation $g\in \N$, we run all the machines in the population until it reaches $min(g, S(m,n) + 1)$ steps. If when the fitness function is called, the machine has performed $k$ steps and is halted, we return $10 \times \frac{k}{S(m,n)}$. If the machine has overtook $S(m,n)$, it get a fitness of 0. Else, if get a fitness of $\frac{k}{S(m,n)}$;
\item the max step value is not known. For each generation, we run all the machines in the population for 10 steps. When the fitness function is called, we return the number of shifts performed if the machine is halted, 0 else.
\end{enumerate}

The structure of this function is detailed in algorithm \ref{alg:fit}.

\begin{algorithm}[h]
\caption[Fitness function]{Fitness function implementation}
\label{alg:fit}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwFunction{random}{random}

\Input{The individual $i$ to evaluate.}
\Output{The fitness given to $i$}
\Begin{
	\If{$S(m,n)$ is known}{
          \If{$i$ is in halt state}{
            \Return{$10 \times \frac{i.\texttt{nb\_shifts}}{S(m,n)}$};
          }\Else{
            \If{$i.\texttt{nb\_shifts} > S(m,n)$}{
            \Return{0}
            } \Else{
              \Return{$\frac{i.\texttt{nb\_shifts}}{S(m,n)}$};
            }
          }
	} \Else{
          \If{$i$ is in halt state}{
            \Return{$i.\texttt{nb\_shifts}$}
          }
          \Else{
            \Return{0}
          }
        }
}
\end{algorithm}

\section{Evolutionary Computing Tool}
This tool has been implemented with the aim to be as general as possible; with C++ in fact is relatively easy to abstract from the type of the individuals. The implementation is inside the file \texttt{population.hpp}.

The idea behind the tool is to hide all the common operations a population method should implement. The main task of the user is to define the type of the individuals, let's say \texttt{I} (that stands for individual), and the genetic operators between individuals (that can be of many kinds). \texttt{I} can be a geometric vector, a neural network or, in our case, a living virtual machine.

In particular, except the representation of the individual, the user must define:

\begin{enumerate}
\item A fitness function. Greater values of this function means that the individual is a ``better'' solution for the problem (in other words we are trying to \textit{maximize} the fitness function). Regarding more what concerns the implementation we searches for a member function of the type \texttt{I}, in particular a function with signature \texttt{double I::fitness(I\&)}.

\item A mutation function. By default the implementation searches for a function with a signature like \texttt{void I::mutate(I\&)}\footnote{Actually the signature is slightly different because we also have as argument the reference to a random number generator. Here we only briefly explain the idea.}.

\item A crossover function. We need here a function like \texttt{void I::crossover(I\&, I\&)}, that is a function that takes two individuals and modify them. In this case, if we want to keep the old individuals, we need to previously copy them.

\item (Optional) A generation function. This function is used to have additional freedom during the execution of the genetic algorithm. It's something the user can decide to do on every individual, at every generation. By default a function like \texttt{void I::generation(I\&, int)}, where the second argument is the generation number.
\end{enumerate}

We always stated ``by default'' because it's possible also to specify other user defined functions (for example not members of the \texttt{I} type). These four functions are then used in the population implementation, where needed.

The skeleton is the classical of the genetic algorithms: for every generation executes the genetic operators and then the selection.

\subsection{When to crossover and when to mutate}

The idea should be that each individual has some probability to be mutated $p_M$ and some probability to be crossed $p_C$. The implementation of the ``with some probability'' is easy (see figure \ref{alg:decision}) but there are some points to clarify.

The first is that if one individual has been chosen for mutation, it can be chosen also for crossover. We thought that this shouldn't have any negative effects, so we allowed it for avoiding checks.

A more complex point is: if one individual has been chosen for crossover, which other individual choose to actually perform the recombination? We tried two possibilities.

The first consists in scanning the population and, after we found probabilistically the first individual, we choose another individual uniformly at random over all the others. There are some drawbacks with this. The second individual is selected without any constraint (i.e. we don't care about the probability $p_C$), so in particular the same individual can be selected many times for crossover. The result is that the probability of crossover is also higher than $p_C$.

The second possibility tries to avoid this problem, using an auxiliary variable to used to store a reference to an individual. When an individual is selected for crossover and this variable is empty, we save this individual. When the next individual is found we have the two individuals where actually perform the recombination. After this, the reference variable is cleaned. Also the second approach has a problem, namely that the crossover happens on individuals with similar rankings. In fact it is very unlikely that, for example, selecting individual 0 for being crossed, we have to wait (the decision fails) until the last individual $N-1$ is reached in the loop. In other words, after selecting an individual for crossover, the second one is not selected with uniform probability among all the others.

\subsection{Selection}
\label{sec:select}


Selection is another very tricky part in this problem. We always used rank selection in our experiments, since often fitness values are not that meaningful (for example comparing halting or non halting machines is very difficult).

Since selection has to be probabilistic our idea has been to use a decision function $d(r)$ that takes as input the rank $r$ of an individual and returns a number in $[0,1]$; then, we proceed making a random decision (kill or not) as explained in section \ref{sec:random}.

Initially we used a sigmoid function, as shown in figure \ref{fig:sigmoid}. The sigmoid is horizontally translated in order to give a certain average number of individuals at every generation\footnote{It's possible to show this average mathematically.}. In particular, the rank where sigmoid has value 0.5 indicates the average size the population will have after a selection step. We chose this function because we wanted more probability to choose the high-ranking individuals, and low probability for the low ranking individuals.
This seems very nice, but in practice it is not. The problem is that it gives too high selection pressure, also if the slope of the sigmoid is very soft (as shown in figure).

\begin{figure}[t]\centering
\includegraphics{figures/decision-function.pdf}
\caption{Example of sigmoid function used to decide if keep or not one individual. On the $x$ axis there is the individual rank. With this function the population size will average 400 individuals (our maximum population size in most tests).}
\label{fig:sigmoid}
\end{figure}

In fact, consider the tails of the sigmoid: here the function takes values very close to zero, or very close to one (exponentially close). This implies that fittest individuals always survive and that worst individuals always get killed. In our case, non halting machines are always dropped, because they are normally in the back of the ranking. Non halting machines are important for us, because our aim is to find machines that are \textit{almost} non halting.
Using other functions is possible, but it remains a problem to have a very low pressure selection and keep the population size under control (not going to zero or infinity).

In order to solve this problem we had also to redesign the fitness function (to give some more importance to this non halting machines), but mainly we had to find some very low pressure selection mechanism.
What we thought is: ``what is the function with the lowest possible selection pressure?''. It is a uniform selection, that is not considering at all the fitness function value. But in this way the search becomes really random, and we don't want this. So we combined this very ``flat'' selection with elitism, and the final selection looks something like this (with reference to algorithm \ref{alg:selection}):

\begin{itemize}
\item Decide a certain number $S$ of individuals to save, for example one fourth of the maximum population size.
\item If the individuals number $N$ is greater than the maximum $M$ the selection happens on the $N-S$ worst individuals. Notice: not $N-M$ (that is only the individuals that exceeds the maximum $M$), but all the individuals that have not been selected by elitism.
\item From this $N-S$ group we kill an average of $N-M$ individuals. As previously introduced in section
\ref{sec:random}, we do this iterating over these individuals and test if a random number in $[0,1]$ is smaller than $\frac{N-M}{N-S}$. This means that an individual is removed with probability $\frac{N-M}{N-S}$, that summed over all the $N-S$ scanned individuals gives the wanted average.
\end{itemize}

Using this selection schema we always have a certain number of not halted machines in the population, so we have very big diversity.

\begin{algorithm}[t]
\caption[Selection procedure]{Selection procedure with elitism}
\label{alg:selection}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\SetKwFunction{random}{random}
%\SetKwFunction{erase}{erase}
%\SetKwFunction{sort}{sort}

\Input{The population $p$, the current population size $N$, the wanted average size $M$ and the number of safe individuals $S$.}
\Output{The remaining individuals in $p$}
\Begin{
	\For{$i\leftarrow 0$ \KwTo $N-1$}{
	%\For{$i \in p[0,N)$}{
		\If{$p[i]$ is a new individual, or is changed}{
			$p[i].value \leftarrow$ \emph{updated fitness value of $p[i]$}\;
		}
	}
	\BlankLine
	\emph{sort $p$ based on the fitness values}\;
	\BlankLine
	\If{$ N < M $}{
		\Return{}\;
	}
	\BlankLine
	$threshold = \frac{N-M}{N-S}$\;
	\For{$i\leftarrow S$ \KwTo $N-1$}{
		\If{\random{} $< threshold$}{
			\emph{erase $i$};
		}
	}
}
\end{algorithm}

\subsection{When to evaluate the fitness function}

Here the point is that we need a fitness value for each individual at each generation, in order to perform selection.
We thought at this problem because our fitness function is quite heavy to compute, and could happen that sometimes an individual remain unchanged from one generation to another. In this case a re-computation of the fitness function should be avoided, and the population method can take care of solving this.

So, since this is a general problem, we used a flag to remember, for every individual, if he has been changed or not. We also save the last fitness value, that is simply a real value. If the flag says that the individual has been changed we need to re-compute the fitness function, otherwise we can use the stored result. For the role of this part in the selection procedure see algorithm \ref{alg:selection}.

This optimization in some cases has shown to be very effective. We can mention a test we made for finding the optimal value of the Ackley's function (located in zero). In this case the computation of the fitness function is relatively heavy compared to the rest of the computation (but maybe not as heavy as our busy beaver problem).
Implementing the simple method explained above we exactly halved the completion time.


\chapter{Results}
\label{chap:results}

We here show the results we get for different alphabet and states set sizes.

Results are presented in tables where lines are indexed by states and column by symbols. Operational states are called $S_0, S_1, \dots$ for easier reading and $H$ denotes the halt state. To find the transition corresponding to the reading of symbol $s$ in state $e$, look at cell in column $s$ on line $S_e$. The content of this cell is, in order, the symbol to write, the direction where to move the reading head ($L$ stands for \emph{left} and $R$ for \emph{right}) and the state to pass to.

\paragraph{Turing machines with 2 symbols and 2 states}

\begin{itemize}
\item Max-step value \cite{rado}: $S(2,2) = 6$ ;
\item Search space size: 20\,736;
\item Machine we found:
\[
\begin{array}[h]{|c|c|c|}
\hline
   &0     &1\\
\hline
S_0& 0RS_1& 1RH\\
\hline
S_1& 1LS_0& 1RS_1\\
\hline
\end{array}
\]
\item Steps it performs before halting: 6 (so it is a busy beaver).
\end{itemize}

\paragraph{Turing machines with 2 symbols and 3 states}

\begin{itemize}
\item Max-step value \cite{rado}: $S(2,3) = 21$;
\item Search space size: 16\,777\,216;
\item Machine we found:
\[
\begin{array}[h]{|c|c|c|c|}
\hline
   & 0    &1\\
\hline
S_0& 1LS_1& 1RH\\
\hline
S_1& 1RS_1& 0LS_2\\
\hline
S_2& 1RS_2& 1RS_0\\
\hline
\end{array}
\]
\item Steps it performs before halting: 21 (so it is a busy beaver).
\end{itemize}


\paragraph{Turing machines with 3 symbols and 2 states}

\begin{itemize}
\item Max-step value: $S(3,2) = 38$;
\item Search space size: 34\,012\,224;
\item Machine we found:
\[
\begin{array}[h]{|c|c|c|c|c|}
\hline
0&   1&   2& 3\\
\hline
S_0& 2LS_1& 0RH& 1RS_1\\
\hline
S_1& 1RS_0& 2RS_1& 1LS_1\\
\hline
\end{array}
\]
\item Steps it performs before halting: 38 (so it is a busy beaver).
\end{itemize}


\paragraph{Turing machines with 2 symbols and 4 states}


\begin{itemize}
\item Max-step value \cite{allen}: $S(2,4) = 107$;
\item Search space size: 25\,600\,000\,000;
\item Machine we found:
\[
\begin{array}[h]{|c|c|c|c|}
  \hline
  &0&   1\\
  \hline
  S_0& 1RS_3& 1LS_3\\
  \hline
  S_1& 1LH& 1LS_2\\
  \hline
  S_2& 1RS_2& 0RS_0\\
  \hline
  S_3& 1LS_0& 0LS_1\\
\hline
\end{array}
\]
\item Steps it performs before halting: 107 (so it is a busy beaver).
\end{itemize}

\paragraph{Turing machines with 4 symbols and 2 states}


\begin{itemize}
\item Max-step value: we only know \cite{michel} that $S(2,4) \geq 3\,932\,964$;
\item Search space size: 110\,075\,314\,176;
\item Machine we found at the time of writing:
\[
\begin{array}[h]{|c|c|c|c|c|}
  \hline
  &  0&   1&   2&   3\\
  \hline
  S_0& 2LS_1& 1RS_0& 3RS_0& 2RH\\
  \hline
  S_1& 3RS_0& 3RS_1& 3LS_1& 1LS_1\\
  \hline
\end{array}
\]
\item Steps it performs before halting: 770 (so it is not a busy beaver).
\end{itemize}

% -> Best machine in the population:
% =========================
% Number of symbols:	4
% Number of states:	2
% Age:			0
% Current state:		H
% Current symbol:		0
% Head position:		74
% Tape size:		101
% Computed steps so far:	770
% Transition table:
%     0:   1:   2:   3:
% S0: 2LS1 1RS0 3RS0 2RSH 
% S1: 3RS0 3RS1 3LS1 1LS1 
% =========================
% Fitness of this machine: 770.0000
% -> Population:
% 	Size:		396
% 	Age:		8000
% 	Halted:		309 machines
% 	Max nb_shifts:	79990
% 	Explored machines:	8320157
% 	Machines space size:	110075314176
% -> Known values:
% 	Lower bound:	3932964
% 	Upper bound:	not known

\chapter{Further work}
\label{chap:fwork}

\section{PSO}
We had no time to test a PSO approach, before writing this report. It would be interesting to try it, of course, but we don't think it would be radically different from the current ideas. And in every case it would be a PSO implementation that has to ``jump'', and not ``fly'', over the search space. This happens because the Turing machine's search space is not continuous, and moreover we have to define by ourselves the particle operations that PSO usually performs.

Our search space is made by the genomes we used in the evolutionary computing approach, not vectors. Discrete and binary PSO approaches has been developed (\cite{dpso}, \cite{binary-pso}) and both of them try to give another interpretation to the vector operations PSO needs in the original version.

Consider for example the PSO step where the velocity of a particle is summed up with the current position. How could be implemented this operation on our Turing machines genome? A possible approach is to interpret the velocity as a probability to change the variable corresponding to that dimension.
So it's something that correspond roughly to a mutation in the evolutionary computing approach (something in between with a crossover and a mutation actually, since the velocity depends on other particles, other genomes).

We don't want to say that PSO, on this problem, would be the same as using the tool we implemented; it's very difficult to make such prevision, but the ideas will be more or less the same, at least for what concerns this redefinition of the operators needed by it.

\section{Optimizations}
A possible optimization regards the virtual machine execution, and in particular it tries to use the following fact:

\begin{Thm}
If a machine $M$ during its execution arrives twice:
\begin{enumerate}
\item in the same state $S$,
\item in the same position on the tape,
\item having the tape unchanged from last time (same size and same content),
\end{enumerate}
means that M will never halt.
\end{Thm}
\begin{proof}
This holds since the transitions are deterministic, so if $M$ showed this behaviour once, it will repeat this infinitely many times.
\end{proof}

In other words this means that $M$ has a ``loop'' of some length $k$ (the number of shifts for going back to the same state $S$). There is a very elegant method for detecting this kind of cycles called Brent's method \cite{brent} (a variant of the Floyd algorithm, credited in \cite{knuth}).

The algorithm keeps track of one previous virtual machine state (so it actually require to double the space occupied by a virtual machine). The algorithm starts saving the state after the first shift. After computing the second shift if checks if the state is the same or not: if it's the same the algorithm just detected a loop, otherwise the virtual machine can compute the next shift. This check happens at every new shift computed by the machine. When the number of shifts is a power of 2, the algorithm stores the current state for the following comparisons.

In this way it's possible to detect loops of any length $k$, if the number of executed shifts is sufficiently large. The nice thing is that detecting a loop not only implies an early stop in a computation that will never end, but also gives more precise informations in terms of fitness function!

But there are of course some drawbacks with this approach:
\begin{enumerate}
\item there is an (increasing) overhead in checking if the current state is equal to the saved one. Increasing because of course the tape size can be bigger and bigger executing the machine.
\item the memory used doubles.
\end{enumerate}

One solution, that also makes the algorithm even more effective, is to check not the whole tape, but just a window of it. This of course is an approximation: limiting the check to a certain portion of the tape can lead to wrong decisions (the machine \textit{seems} to have come back to the same state, but it is not).
But of course the bigger is this window, the more precise is this approximation. And having a constant window size, makes the state check constant time (so not increasing with the tape size).

Another solution could be to save an hash of the tape, instead of the full tape. This is very memory effective but, because of the hash collisions can also be inexact. Also a combination of the two approaches would be very interesting to try.



\chapter{Outcome}
\label{chap:outcome}

With reference to the implementation we realized a program to run Turing machines, and an evolutionary computing tool that can be used also for other contexts. Moreover the implementation seems to be quite fast.
With these tools we found busy beavers for all known cases. The other cases are computationally very expensive and need further examination (or optimizations).
The problem we wanted to solve is very challenging and probably we can't do much more than this: solving these complex cases with a computer simulation is not tractable in practice.

\appendix
\chapter{Additional Work}

\input{statistics.tex}

\bibliographystyle{plain}
\bibliography{report}

\end{document}